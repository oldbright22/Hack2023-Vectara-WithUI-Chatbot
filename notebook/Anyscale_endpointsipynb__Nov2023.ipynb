{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzvRuJJSHpo1"
   },
   "outputs": [],
   "source": [
    "#%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opentelemetry-util-http==0.42b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting anyio<4,>=3.5.0 (from openai)\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.25.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.5 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.2.0-py3-none-any.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.9/219.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, pydantic-core, h11, distro, anyio, annotated-types, pydantic, httpcore, httpx, openai\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "Successfully installed annotated-types-0.6.0 anyio-3.7.1 distro-1.8.0 h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 openai-1.2.0 pydantic-2.4.2 pydantic-core-2.10.1 tqdm-4.66.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xmJpvFhHGgot"
   },
   "outputs": [],
   "source": [
    "#%pip install langflow==0.5.7\n",
    "#!python -m langflow\n",
    "#%pip install 'openai<0.28.0,>=0.27.8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JshLsEYK9I1"
   },
   "source": [
    "## Testing The OpenAI call with Anyscale Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x-97Io4RnffZ"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ShakeSwift\n",
      "2. HealthMix\n",
      "3. CompactMilkshaker\n",
      "4. FitBlend\n",
      "5. QuickMix\n",
      "6. ShakeMate\n",
      "7. SlimShake\n",
      "8. MilkshakeExpress\n",
      "9. NutriShake\n",
      "10. SwiftBlend.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "#from openai.types import chat\n",
    "#import openai\n",
    "#openai.api_key = \"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\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "\n",
    "system_content = \"You will be provided with a product description and seed words. Your task is to generate potential product names.\"\n",
    "user_content = \"Product description: A home milkshake maker. Seed words: fast, healthy, compact.\"\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature=0.7\n",
    ")\n",
    "#product_names = chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "#print(\"Results from the OpenAI endpoint:\\n\", product_names)\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XYF708dMpGLE"
   },
   "outputs": [],
   "source": [
    "#It should return an error due to changes and openai Update recently , if it didn't then it's fixed\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "#https://huggingface.co/meta-llama  -- here is where i can find the actual models names\n",
    "#chat_completion = client.chat.completions.create(\n",
    "#    #api_base = \"https://api.endpoints.anyscale.com/v1\",   TypeError: Completions.create() got an unexpected keyword argument 'api_base'\n",
    "#    #api_key=\"esecret_hanjm9lbkdr62f7csy3fem5fvy\",      TypeError: Completions.create() got an unexpected keyword argument 'api_key'  \n",
    "#    model=\"Llama-2-70b-chat-hf\",                         #The model `meta-llama/Llama-2-70b-chat-hf` does not exist\n",
    "#    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "#              {\"role\": \"user\", \"content\": user_content}],\n",
    "#    temperature=0.7\n",
    "#)\n",
    "\n",
    "#product_names = chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "#print(\"Results from Anyscale Endpoint:\\n\", product_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU-5cmrqLz9v"
   },
   "source": [
    "# Anyscale Endpoints direct Query\n",
    "This is the direct connection to access Open source LLM like LLama2-70b, llama2-13b etc If using Premium version of anyscale you could finetune models and use custom models. you can define a function to avoid rewriting the code just tweak with some indentation using *def* keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oExOVYptxslR"
   },
   "outputs": [],
   "source": [
    "query = 'who are you?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rQBdpioXxCuT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot Response:\n",
      "  Greetings! I am Kamal, a helpful doctor. I am here to assist you with any medical-related questions or concerns you may have. How can I be of assistance to you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "#api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "#token = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = \"https://api.endpoints.anyscale.com/v1\"\n",
    "token = \"esecret_4fvbprd1pf4t1fziay6fpz1elg\"\n",
    "url = f\"{api_base}/chat/completions\"\n",
    "body = {\n",
    "  \"model\": \"meta-llama/Llama-2-70b-chat-hf\",\n",
    "  \"messages\": [{\"role\": \"system\", \"content\": \"Your name is Kamal and you are a helpful doctor.\"}, {\"role\": \"user\", \"content\": query}],\n",
    "  \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "response = s.post(url, headers={\"Authorization\": f\"Bearer {token}\"}, json=body)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_json = response.json()\n",
    "    chatbot_response = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"Chatbot Response:\")\n",
    "    print(chatbot_response)\n",
    "else:\n",
    "    print(f\"Request failed with status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/python/3.10.8/lib/python3.10/site-packages (0.0.332)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/python/3.10.8/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: transformers in /usr/local/python/3.10.8/lib/python3.10/site-packages (4.35.0)\n",
      "Collecting chroma\n",
      "  Using cached Chroma-0.2.0-py3-none-any.whl\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.16-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (0.0.62)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (0.104.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0.post1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from chromadb) (4.8.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (1.16.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (1.59.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (28.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/codespace/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/codespace/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/codespace/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.23.4)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/codespace/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.6.4)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/python/3.10.8/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
      "Requirement already satisfied: pytest-subtests<0.12.0,>=0.11.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langsmith<0.1.0,>=0.0.52->langchain) (0.11.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/python/3.10.8/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/python/3.10.8/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /usr/local/python/3.10.8/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.8.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.61.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.21.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: pytest>=7.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain) (7.4.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.0)\n",
      "Requirement already satisfied: iniconfig in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain) (1.3.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain) (2.0.1)\n",
      "Using cached chromadb-0.4.16-py3-none-any.whl (496 kB)\n",
      "Installing collected packages: chroma, chromadb\n",
      "Successfully installed chroma-0.2.0 chromadb-0.4.16\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain  python-dotenv  transformers  chroma  chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping Chroma as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping ChromaDB as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping pysqlite3-binary as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping sqlite3 as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall Chroma ChromaDB pysqlite3-binary sqlite3 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Vectara\n",
    "\n",
    "#from langchain.retrievers import RAGRetriever\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.llms import OpenAI #GPT\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(OPENAI_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a text file 'sample.txt' that you want to load\n",
    "file_path = 'state_of_the_union.txt'\n",
    "\n",
    "# Create an instance of TextLoader\n",
    "text_loader = TextLoader(file_path)\n",
    "\n",
    "# Use the load method to read the text from the file\n",
    "documents = text_loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "#Getting this error --> RuntimeError: Your system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.\n",
    "#docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "489591653\n",
      "4\n",
      "zwt_HS6TZYlyetSIm6hfFphiP_eWGEuTtPTn4eQPnw\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('OPENAI_API_KEY'))\n",
    "print(os.getenv('VECTARA_CUSTOMER_ID'))\n",
    "print(os.getenv('VECTARA_CORPUS_ID'))\n",
    "print(os.getenv('VECTARA_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'Error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m question \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat is this document about?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m answer \u001b[39m=\u001b[39m qa({\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mWhat is this document about?\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(answer)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:139\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    138\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(question)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    140\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, question\u001b[39m=\u001b[39;49mquestion, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child()\n\u001b[1;32m    141\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_source_documents:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/base.py:510\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    511\u001b[0m         _output_key\n\u001b[1;32m    512\u001b[0m     ]\n\u001b[1;32m    514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:122\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m--> 122\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    123\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:171\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/llm.py:298\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \n\u001b[1;32m    286\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39m        completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/llm.py:108\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    105\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m    106\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 108\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/chains/llm.py:120\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    121\u001b[0m         prompts,\n\u001b[1;32m    122\u001b[0m         stop,\n\u001b[1;32m    123\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    124\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/llms/base.py:507\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 507\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/llms/base.py:656\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    646\u001b[0m         dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    654\u001b[0m     )\n\u001b[1;32m    655\u001b[0m ]\n\u001b[0;32m--> 656\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    657\u001b[0m     prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    658\u001b[0m )\n\u001b[1;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/llms/base.py:544\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 544\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    545\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/llms/base.py:531\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 531\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    532\u001b[0m             prompts,\n\u001b[1;32m    533\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    534\u001b[0m             \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    535\u001b[0m             run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    536\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    537\u001b[0m         )\n\u001b[1;32m    538\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    539\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    540\u001b[0m     )\n\u001b[1;32m    541\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/llms/openai.py:401\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\n\u001b[1;32m    402\u001b[0m         \u001b[39mself\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m_prompts, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    403\u001b[0m     )\n\u001b[1;32m    404\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/llms/openai.py:109\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m retry_decorator \u001b[39m=\u001b[39m _create_retry_decorator(llm, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    111\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/llms/openai.py:92\u001b[0m, in \u001b[0;36m_create_retry_decorator\u001b[0;34m(llm, run_manager)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m     91\u001b[0m errors \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 92\u001b[0m     openai\u001b[39m.\u001b[39;49merror\u001b[39m.\u001b[39mTimeout,\n\u001b[1;32m     93\u001b[0m     openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAPIError,\n\u001b[1;32m     94\u001b[0m     openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAPIConnectionError,\n\u001b[1;32m     95\u001b[0m     openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mRateLimitError,\n\u001b[1;32m     96\u001b[0m     openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mServiceUnavailableError,\n\u001b[1;32m     97\u001b[0m ]\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m create_base_retry_decorator(\n\u001b[1;32m     99\u001b[0m     error_types\u001b[39m=\u001b[39merrors, max_retries\u001b[39m=\u001b[39mllm\u001b[39m.\u001b[39mmax_retries, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    100\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'error'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m        \u001b[39mprint\u001b[39m(answer)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m        \u001b[39m# RetrievalQA.from_llm combines a large language model with a retriever for question answering from datastore\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m        \u001b[39m#retrieval_qa = RetrievalQA.from_llm(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m        \u001b[39m#llm=OpenAI(),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m        \n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m        \u001b[39m#print(answer2)       \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mexcept\u001b[39;00m openai\u001b[39m.\u001b[39;49mError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bzany-fortnight-w6pgqx7r66qfvjr4/workspaces/Hack2023-Vectara-RAG/Anyscale_endpointsipynb__Nov2023.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mprint\u001b[39m(e)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'Error'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "try:\n",
    "       # Your code to interact with the openai API here\n",
    "       OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "       VECTARA_CUSTOMER_ID = os.getenv('VECTARA_CUSTOMER_ID')\n",
    "       VECTARA_CORPUS_ID = os.getenv('VECTARA_CORPUS_ID')\n",
    "       VECTARA_API_KEY = os.getenv('VECTARA_API_KEY')\n",
    "\n",
    "       # Load data (docs) into vectara DB\n",
    "       vectara  = Vectara.from_documents(documents, embedding=None)\n",
    "\n",
    "\n",
    "        #Initialize the GPT model, for example using the `X` class from Langchain.\n",
    "        #llm = GPT()   OR  llm = OpenAI()\n",
    "\n",
    "\n",
    "       # Initialize the RAGRetriever, this requires specifying the dataset/index to retrieve from.\n",
    "       # Under vectara - https://console.vectara.com/console/corpus/4/overview\n",
    "       # I have the following data store\n",
    "       # Assuming `rag_retriever` is a RAGRetriever that you've set up with your corpus.\n",
    "\n",
    "       #rag_retriever = RAGRetriever(\n",
    "       #index_name='vectara-flowise-datastore',\n",
    "       #use_dummy_dataset=False # if true, uses a small dummy dataset for testing.\n",
    "       #)\n",
    "\n",
    "       ##Loaded from the document  \"state of the union\" \n",
    "       qa = RetrievalQA.from_llm(llm=OpenAI(), retriever = vectara.as_retriever())\n",
    "\n",
    "       question = \"What is this document about?\"\n",
    "       answer = qa({\"query\":\"What is this document about?\"})\n",
    "\n",
    "       #https://python.langchain.com/docs/use_cases/question_answering/vector_db_qa  FROM chain_type\n",
    "       #query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "       #qa.run(query)\n",
    "       \n",
    "       print(answer)\n",
    "\n",
    "       #Good about handling memory\n",
    "       #https://python.langchain.com/docs/use_cases/question_answering/code_understanding\n",
    "\n",
    "       #qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.as_retriever(search_type=\"mmr\", search_kwargs={'fetch_k': 30}), return_source_documents=True)\n",
    "\n",
    "       # docsearch.as_retriever(search_type=\"mmr\")\n",
    "\n",
    "       # RetrievalQA.from_llm combines a large language model with a retriever for question answering from datastore\n",
    "       #retrieval_qa = RetrievalQA.from_llm(\n",
    "       #llm=OpenAI(),\n",
    "       #retriever=rag_retriever,\n",
    "       #preprocessors=[], # List any preprocessors you want to use.\n",
    "       #postprocessors=[] # List any postprocessors you want to use.\n",
    "       #)\n",
    "\n",
    "       # Now you can use `retrieval_qa` to answer questions with support from the retriever.\n",
    "       #question2 = \"What is this document about?\"\n",
    "\n",
    "       # This method will retrieve documents relevant to the question and then use the llm to generate an answer.\n",
    "       #answer2 = retrieval_qa.answer(question2)\n",
    "       \n",
    "       #print(answer2)       \n",
    "\n",
    "except openai.Error as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('state_of_the_union.txt')\n",
    "#documents = loader.load()\n",
    "#vectara  = Vectara.from_documents(documents)\n",
    "\n",
    "#qa = RetrievalQA.from_llm(llm=OpenAI(), retriever=vectara.as_retriever())\n",
    "\n",
    "#print(qa({“query”:  “According to the document, what did Vladimir Putin miscalculate?”}))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
